<!DOCTYPE HTML>
<html lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <title>Daan de Geus</title>

    <meta name="author" content="Daan de Geus">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <meta property="og:type" content="website">
    <meta property="og:title" content="Daan de Geus">
    <meta property="og:description" content="Assistant Professor at Eindhoven University of Technology.">
    <meta property="og:url" content="https://daandegeus.com/">
    <meta property="og:image" content="https://daandegeus.com/img/ddegeus.jpg">

    <!-- <link rel="shortcut icon" href="images/favicon/favicon.ico" type="image/x-icon"> -->
    <link rel="stylesheet" type="text/css" href="stylesheet.css">
    
  </head>

  <body>
    <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr style="padding:0px">
        <td style="padding:0px">


          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr style="padding:0px">
              <td style="padding:2.5%;width:63%;vertical-align:middle">
                <p class="name" style="text-align: center;">
                  Daan de Geus
                </p>
                <p>
    I'm an assistant professor in the <a href="https://www.tue.nl/en/research/research-groups/signal-processing-systems/mobile-perception-systems-lab">Mobile Perception Systems Lab</a> at the <a href="https://www.tue.nl/en/">Eindhoven University of Technology</a> (TU/e), in the Netherlands.
	  I did my PhD at TU/e, and was a visiting PostDoc in the <a href="https://www.vision.rwth-aachen.de/">Computer Vision Lab</a> at RWTH Aachen University, headed by Prof. Dr. Bastian Leibe.
    My research focuses on machine learning for visual and multimodal scene understanding.
                </p>
                <p style="text-align:center">
                  <!-- <a href="mailto:TBD">Email</a> &nbsp;/&nbsp; -->
                  <!-- <a href="data/CV.pdf">CV</a> &nbsp;/&nbsp; -->
                  <!-- <a href="data/bio.txt">Bio</a> &nbsp;/&nbsp; -->
                  <a href="https://scholar.google.com/citations?user=4gX3HRoAAAAJ">Scholar</a> &nbsp;/&nbsp;
                  <a href="https://twitter.com/dcdegeus">Twitter</a> &nbsp;/&nbsp;
                  <a href="https://bsky.app/profile/dcdegeus.bsky.social">Bluesky</a> &nbsp;/&nbsp;
                  <a href="https://github.com/ddegeus/">Github</a>
                </p>
              </td>
              <td style="padding:2.5%;width:37%;max-width:37%">
                <img style="width:100%;max-width:100%;object-fit: cover; border-radius: 50%;" alt="Profile photo of Daan de Geus" src="img/ddegeus.jpg" class="hoverZoomLink">
              </td>
            </tr>
          </tbody></table>

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <tr>
              <td style="padding:16px;width:100%;vertical-align:middle">
                <h2>News</h2>
                <p>
                  <strong>[2025/10]</strong> Honored to be selected as a <a href="https://neurips.cc/Conferences/2025/ProgramCommittee#top-reviewer">top reviewer</a> for NeurIPS 2025.<br> 
                  <strong>[2025/09]</strong> We have released the code and models for <a href="https://github.com/MKnoche/DONUT">DONUT</a>. <br> 
                  <strong>[2025/09]</strong> <a href="https://arxiv.org/abs/2509.19082">Sa2VA-i</a> has achieved the 3rd place on the <a href="https://lsvos.github.io/">ICCV 2025 RVOS Challenge</a>. Code and models are <a href="https://github.com/kumuji/sa2va-i">available</a>.<br>
                  <strong>[2025/07]</strong> I started as an assistant professor at the <a href="https://www.tue.nl/en/research/research-groups/signal-processing-systems/mobile-perception-systems-lab">MPS Lab</a> of TU/e.<br>
                  <strong>[2025/06]</strong> <a href="https://mknoche.github.io/DONUT/">DONUT</a> has been accepted to ICCV 2025. <br>
                  <strong>[2025/05]</strong> We have won the <a href="https://kaldir.vc.in.tum.de/scannetpp/cvpr2025">CVPR 2025 ScanNet++ Challenge</a> with <a href="https://visualcomputinginstitute.github.io/DITR/">DITR</a>. <br>
                  <strong>[2025/03]</strong> <a href="https://github.com/tue-mps/eomt">EoMT</a> has been accepted to CVPR 2025. <br>
                </p>
              </td>
            </tr>
          </tbody></table>


          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <tr>
              <td style="padding:16px;width:100%;vertical-align:middle">
                <h2>Selected publications</h2>
                <p>See all publications <a href="publications/">here</a>.</p>
              </td>
            </tr>
          </tbody></table>
    
    
          <table style="width:100%;border:0px;border-spacing:0px 10px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

      <!-- DONUT -->
      <tr>
        <td style="padding:16px;width:20%;vertical-align:middle">
          <div class="pubimg">
            <img src='img/donut.png' width="120" class="center">
          </div>
        </td>
        <td style="padding:8px;width:80%;vertical-align:middle">
          <a href="https://mknoche.github.io/DONUT/">
            <span class="papertitle">DONUT: A Decoder-Only Model for Trajectory Prediction</span>
          </a>
          <br>
          <a href="https://www.vision.rwth-aachen.de/person/225/">Markus Knoche</a>,
          <strong>Daan de Geus</strong>,
          <a href="https://www.vision.rwth-aachen.de/person/1/">Bastian Leibe</a>
          <br>
          <em>ICCV</em>, 2025
      
          <br>
          <a href="https://mknoche.github.io/DONUT/">Project page</a>
          /
          <a href="https://arxiv.org/abs/2506.06854">arXiv</a>
          /
          <!-- <a href="#">CVF</a> -->
          <!-- / -->
          <a href="https://github.com/MKnoche/DONUT">Code</a>
          /
          <a href="https://www.youtube.com/watch?v=6EwE89CN4Ns">YouTube</a>
          <p></p>
          <p>
          We predict future trajectories autoregressively with a decoder-only model, to treat historical and future trajectories identically.
          </p>
        </td>
      </tr>

      <!-- EoMT -->
      <tr>
        <td style="padding:16px;width:20%;vertical-align:middle">
          <div class="pubimg">
            <img src='img/eomt.jpg' width="180" class="center">
          </div>
        </td>
        <td style="padding:8px;width:80%;vertical-align:middle">
          <a href="https://www.tue-mps.org/eomt/">
            <span class="papertitle">Your ViT is Secretly an Image Segmentation Model</span>
          </a>
          <br>
          <a href="https://tommiekerssies.com/">Tommie Kerssies</a>,
          <a href="https://scholar.google.com/citations?user=Pr4XHRAAAAAJ">Niccol&ograve; Cavagnero</a>, 
          <a href="hhttps://scholar.google.de/citations?user=V0iMeYsAAAAJ">Alexander Hermans</a>,
          <a href="https://scholar.google.com/citations?user=q7sm490AAAAJ">Narges Norouzi</a>, <br>
          <a href="https://www.giuseppeaverta.me/">Giuseppe Averta</a>,
          <a href="https://www.vision.rwth-aachen.de/person/1/">Bastian Leibe</a>, 
          <a href="https://www.tue.nl/en/research/researchers/gijs-dubbelman">Gijs Dubbelman</a>,
          <strong>Daan de Geus</strong>
          <br>
          <em>CVPR</em>, 2025 <font color="red"><strong>(Highlight Paper)</strong></font>
      
          <br>
          <a href="https://www.tue-mps.org/eomt/">Project page</a>
          /
          <a href="https://arxiv.org/abs/2503.19108">arXiv</a>
          /
          <a href="https://openaccess.thecvf.com/content/CVPR2025/html/Kerssies_Your_ViT_is_Secretly_an_Image_Segmentation_Model_CVPR_2025_paper">CVF</a>
          /
          <a href="https://github.com/tue-mps/eomt">Code</a>
          <p></p>
          <p>
          With a sufficiently large model and extensive pre-training, complex task-specific components are not necessary for image segmentation.
          </p>
        </td>
      </tr>


      <!-- DITR -->
      <tr>
        <td style="padding:16px;width:20%;vertical-align:middle">
          <div class="pubimg">
            <img src='img/ditr.png' width="180">
          </div>
        </td>
        <td style="padding:8px;width:80%;vertical-align:middle">
          <a href="https://visualcomputinginstitute.github.io/DITR/">
            <span class="papertitle">DINO in the Room: Leveraging 2D Foundation Models for 3D Segmentation</span>
          </a>
          <br>
          <a href="https://ka.codes/">Karim Abou Zeid</a>*,
          <a href="https://github.com/YilmazKadir/">Kadir Yilmaz</a>*, 
          <strong>Daan de Geus</strong>,
          <a href="https://scholar.google.com/citations?user=V0iMeYsAAAAJ">Alexander Hermans</a>, <br>
          <a href="https://scholar.google.com/citations?user=vpn6QN0AAAAJ">David Adrian</a>,
          <a href="https://scholar.google.com/citations?user=s3_VpQYAAAAJ">Timm Linder</a>,
          <a href="https://www.vision.rwth-aachen.de/person/1/">Bastian Leibe</a>
          <br>
          <em>arXiv</em>, 2025
      
          <br>
          <a href="https://visualcomputinginstitute.github.io/DITR/">Project page</a>
          /
          <a href="https://arxiv.org/abs/2503.18944">arXiv</a>
          /
          <a href="https://github.com/VisualComputingInstitute/DITR">Code (soon)</a>
          <p></p>
          <p>
          We inject image-based DINOv2 features into a point cloud model to dramatically enhance 3D segmentation performance.
          </p>
        </td>
      </tr>


      <!-- Diffusion-e2e-ft -->
      <tr onmouseout="e2eft_stop()" onmouseover="e2eft_start()">
        <td style="padding:16px;width:20%;vertical-align:middle">
          <div class="one">
            <div class="two" id='e2eft_image'>
              <img src='img/e2eft_norm_after.png' width="180"></div>
            <img src='img/e2eft_norm_before.png' width="180">
          </div>
          <script type="text/javascript">
            function e2eft_start() {
              document.getElementById('e2eft_image').style.opacity = "1";
            }

            function e2eft_stop() {
              document.getElementById('e2eft_image').style.opacity = "0";
            }
            e2eft_stop()
          </script>
        </td>
        <td style="padding:8px;width:80%;vertical-align:middle">
          <a href="https://gonzalomartingarcia.github.io/diffusion-e2e-ft/">
            <span class="papertitle">Fine-Tuning Image-Conditional Diffusion Models is Easier than You Think</span>
          </a>
          <br>
          <a href="https://huggingface.co/GonzaloMG">Gonzalo Martin Garcia</a>*, 
          <a href="https://ka.codes/">Karim Abou Zeid</a>*,
          <a href="https://github.com/Schmiddo">Christian Schmidt</a>*, 
          <strong>Daan de Geus</strong>, <br>
          <a href="https://scholar.google.com/citations?user=V0iMeYsAAAAJ">Alexander Hermans</a>,
          <a href="https://www.vision.rwth-aachen.de/person/1/">Bastian Leibe</a>
          <br>
          <em>WACV</em>, 2025 <font color="red"><strong>(Oral Presentation)</strong></font>
      
          <br>
          <a href="https://gonzalomartingarcia.github.io/diffusion-e2e-ft/">Project page</a>
          /
          <a href="https://arxiv.org/abs/2409.11355">arXiv</a>
          /
          <a href="https://openaccess.thecvf.com/content/WACV2025/html/Garcia_Fine-Tuning_Image-Conditional_Diffusion_Models_is_Easier_than_You_Think_WACV_2025_paper">CVF</a>
          /
          <a href="https://github.com/VisualComputingInstitute/diffusion-e2e-ft">Code</a>
          /
          <a href="https://huggingface.co/spaces/GonzaloMG/marigold-e2e-ft-depth">Demo</a>
          <p></p>
          <p>
          Repurposing diffusion models for geometry estimation is as simple as end-to-end fine-tuning.
        </p>
        </td>
      </tr>

      <!-- ALGM -->
      <tr onmouseout="algm_stop()" onmouseover="algm_start()">
        <td style="padding:16px;width:20%;vertical-align:middle">
          <div class="one">
            <div class="two" id='algm_image'>
              <img src='img/algm_after.png' width="180"></div>
            <img src='img/algm_before.png' width="180">
          </div>
          <script type="text/javascript">
            function algm_start() {
              document.getElementById('algm_image').style.opacity = "1";
            }

            function algm_stop() {
              document.getElementById('algm_image').style.opacity = "0";
            }
            algm_stop()
          </script>
        </td>
        <td style="padding:8px;width:80%;vertical-align:middle">
          <a href="https://www.tue-mps.org/ALGM/">
            <span class="papertitle">ALGM: Adaptive Local-then-Global Token Merging for Efficient Semantic Segmentation with Plain Vision Transformers</span>
          </a>
          <br>
          <a href="https://scholar.google.com/citations?user=q7sm490AAAAJ">Narges Norouzi</a>, 
          <a href="https://scholar.google.com/citations?user=5tqsZtYAAAAJ">Svetlana Orlova</a>,
          <strong>Daan de Geus</strong>,
          <a href="https://www.tue.nl/en/research/researchers/gijs-dubbelman">Gijs Dubbelman</a>
          <br>
          <em>CVPR</em>, 2024
      
          <br>
          <a href="https://www.tue-mps.org/ALGM/">Project page</a>
          /
          <a href="https://arxiv.org/abs/2406.09936">arXiv</a>
          /
          <a href="https://openaccess.thecvf.com/content/CVPR2024/html/Norouzi_ALGM_Adaptive_Local-then-Global_Token_Merging_for_Efficient_Semantic_Segmentation_with_CVPR_2024_paper">CVF</a>
          /
          <a href="https://github.com/tue-mps/algm-segmenter">Code</a>
          <p></p>
          <p>
          By merging patch tokens locally and then globally, the throughput of ViT-based segmentation models can be greatly enhanced while preserving accuracy.
        </p>
        </td>
      </tr>


      <!-- CTS -->
      <tr onmouseout="cts_stop()" onmouseover="cts_start()">
        <td style="padding:16px;width:20%;vertical-align:middle">
          <div class="one">
            <div class="two" id='cts_image'>
              <img src='img/cts_after.png' width="180"></div>
            <img src='img/cts_before.png' width="180">
          </div>
          <script type="text/javascript">
            function cts_start() {
              document.getElementById('cts_image').style.opacity = "1";
            }

            function cts_stop() {
              document.getElementById('cts_image').style.opacity = "0";
            }
            cts_stop()
          </script>
        </td>
        <td style="padding:8px;width:80%;vertical-align:middle">
          <a href="https://www.tue-mps.org/CTS/">
            <span class="papertitle">Content-aware Token Sharing for Efficient Semantic Segmentation with Vision Transformers</span>
          </a>
          <br>
          <a href="https://chenyang-lu.github.io/">Chenyang Lu</a>*,
          <strong>Daan de Geus</strong>*,
          <a href="https://www.tue.nl/en/research/researchers/gijs-dubbelman">Gijs Dubbelman</a>
          <br>
          <em>CVPR</em>, 2023
      
          <br>
          <a href="https://www.tue-mps.org/CTS/">Project page</a>
          /
          <a href="https://arxiv.org/abs/2306.02095">arXiv</a>
          /
          <a href="https://openaccess.thecvf.com/content/CVPR2023/html/Lu_Content-Aware_Token_Sharing_for_Efficient_Semantic_Segmentation_With_Vision_Transformers_CVPR_2023_paper">CVF</a>
          /
          <a href="https://github.com/tue-mps/cts-segmenter">Code</a>
          <p></p>
          <p>
          A small pre-processing network identifies image patches that can share a token in a ViT-based segmentation model, to improve efficiency without harming the accuracy.
        </p>
        </td>
      </tr>

    </tbody></table>

    <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr>
        <td style="padding:0px">
          <br>
          <p style="text-align:right;font-size:small;">
            Based on <a href="https://github.com/jonbarron/jonbarron.github.io">Jon Barron's website</a>.
          </p>
        </td>
      </tr>
    </tbody></table>

  </td>
  </tr>
  </tbody></table>
  </body>
</html>
