<!DOCTYPE HTML>
<html lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <title>Daan de Geus - Publications</title>

    <meta name="author" content="Daan de Geus">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <meta property="og:type" content="website">
    <meta property="og:title" content="Daan de Geus - Publications">
    <meta property="og:description" content="List of publications of Daan de Geus.">
    <meta property="og:url" content="https://daandegeus.com/publications/">

    <!-- <link rel="shortcut icon" href="images/favicon/favicon.ico" type="image/x-icon"> -->
    <link rel="stylesheet" type="text/css" href="../stylesheet.css">
    
  </head>

  <body>
    <div id="top"></div>

    <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
        <p>
            <a href="../">&lArr; Back to the homepage</a>
        </p>
            
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr style="padding:0px">
            <td style="padding:2.5%;width:100%;vertical-align:middle">
                <p class="publications"  style="text-align: center;">
                    All publications
                </p>
            </td>
            </tr>

            <tr>
              <td style="vertical-align:top">
                <p>
                <strong>2026</strong><br>
                <ul>

                    <li>
                        <strong>DINO in the Room: Leveraging 2D Foundation Models for 3D Segmentation</strong><br>
                        Karim Abou Zeid, Kadir Yilmaz, <strong>Daan de Geus</strong>, Alexander Hermans, David Adrian, Timm Linder, Bastian Leibe<br>
                        <em>3DV</em>, 2026<br>
                        <a href="https://visualcomputinginstitute.github.io/DITR/">Project page</a>
                        /
                        <a href="https://arxiv.org/abs/2503.18944">arXiv</a>
                        /
                        <a href="https://github.com/VisualComputingInstitute/DITR">Code (soon)</a>
                    </li>

                </ul>
                </p>

              </td>
            </tr>

            <tr>
              <td style="vertical-align:top">
                <p>
                <strong>2025</strong><br>
                <ul>
                    <li>
                        <strong>DONUT: A Decoder-Only Model for Trajectory Prediction</strong><br>
                        Markus Knoche, <strong>Daan de Geus</strong>, Bastian Leibe <br>
                        <em>ICCV</em>, 2025 <br>
                        <a href="https://mknoche.github.io/DONUT/">Project page</a>
                        /
                        <a href="https://arxiv.org/abs/2506.06854">arXiv</a>
                        /
                        <!-- <a href="#">CVF</a> -->
                        <!-- / -->
                        <a href="https://github.com/MKnoche/DONUT">Code</a>
                        /
                        <a href="https://www.youtube.com/watch?v=6EwE89CN4Ns">YouTube</a>
                    </li>

                    <li>
                        <strong>Your ViT is Secretly an Image Segmentation Model</strong><br>
                        Tommie Kerssies, Niccol√≤ Cavagnero, Alexander Hermans, Narges Norouzi, <br> Giuseppe Averta, Bastian Leibe, Gijs Dubbelman, <strong>Daan de Geus</strong> <br>
                        <em>CVPR</em>, 2025 <font color="red"><strong>(Highlight Paper)</strong></font><br>
                        <a href="https://www.tue-mps.org/eomt/">Project page</a>
                        /
                        <a href="https://arxiv.org/abs/2503.19108">arXiv</a>
                        /
                        <a href="https://openaccess.thecvf.com/content/CVPR2025/html/Kerssies_Your_ViT_is_Secretly_an_Image_Segmentation_Model_CVPR_2025_paper">CVF</a>
                        /
                        <a href="https://github.com/tue-mps/eomt">Code</a>
                    </li>

                    <li>
                        <strong>Fine-Tuning Image-Conditional Diffusion Models is Easier than You Think</strong><br>
                        Gonzalo Martin Garcia, Karim Abou Zeid, Christian Schmidt, <strong>Daan de Geus</strong>, Alexander Hermans, Bastian Leibe<br>
                        <em>WACV</em>, 2025 <font color="red"><strong>(Oral Presentation)</strong></font><br>
                        <a href="https://gonzalomartingarcia.github.io/diffusion-e2e-ft/">Project page</a>
                        /
                        <a href="https://arxiv.org/abs/2409.11355">arXiv</a>
                        /
                        <a href="https://openaccess.thecvf.com/content/WACV2025/html/Garcia_Fine-Tuning_Image-Conditional_Diffusion_Models_is_Easier_than_You_Think_WACV_2025_paper">CVF</a>
                        /
                        <a href="https://github.com/VisualComputingInstitute/diffusion-e2e-ft">Code</a>
                        /
                        <a href="https://huggingface.co/spaces/GonzaloMG/marigold-e2e-ft-depth">Demo</a>
                    </li>

                    <li>
                        <strong>How Important are Videos for Training Video LLMs?</strong><br>
                        George Lydakis, Alexander Hermans, Ali Athar, <strong>Daan de Geus</strong>, Bastian Leibe<br>
                        <em>arXiv</em>, 2025 (Presented at <em>CVPR 2025 Workshop on Video Large Language Models</em>)<br>
                        <a href="https://visualcomputinginstitute.github.io/videollm-pseudovideo-training/">Project page</a>
                        /
                        <a href="https://www.arxiv.org/abs/2506.06928">arXiv</a>
                    </li>

                    <li>
                        <strong>3rd Place Report of LSVOS 2025 MeViS Track: Sa2VA-i: Improving Sa2VA Results with Consistent Training and Inference</strong><br>
                        Alexey Nekrasov, Ali Athar, <strong>Daan de Geus</strong>, Alexander Hermans, Bastian Leibe<br>
                        <em>arXiv</em>, 2025 (3rd place at <em>RVOS track of LSVOS Challenge at ICCV 2025</em>)<br>
                        <a href="https://arxiv.org/abs/2509.19082">arXiv</a>
                        /
                        <a href="https://github.com/kumuji/sa2va-i">Code</a>
                    </li>

                </ul>
                </p>

              </td>
            </tr>

            <tr>
              <td style="vertical-align:top">
                <p>
                <strong>2024</strong><br>
                <ul>
                    <li>
                        <strong>ALGM: Adaptive Local-then-Global Token Merging for Efficient Semantic Segmentation with Plain Vision Transformers</strong><br>
                        Narges Norouzi, Svetlana Orlova, <strong>Daan de Geus</strong>, Gijs Dubbelman<br>
                        <em>CVPR</em>, 2024 <br>
                        <a href="https://www.tue-mps.org/ALGM/">Project page</a>
                        /
                        <a href="https://arxiv.org/abs/2406.09936">arXiv</a>
                        /
                        <a href="https://openaccess.thecvf.com/content/CVPR2024/html/Norouzi_ALGM_Adaptive_Local-then-Global_Token_Merging_for_Efficient_Semantic_Segmentation_with_CVPR_2024_paper">CVF</a>
                        /
                        <a href="https://github.com/tue-mps/algm-segmenter">Code</a>
                    </li>

                    <li>
                        <strong>Task-aligned Part-aware Panoptic Segmentation through Joint Object-Part Representations</strong><br>
                        <strong>Daan de Geus</strong>, Gijs Dubbelman<br>
                        <em>CVPR</em>, 2024 <br>
                        <a href="https://tue-mps.github.io/tapps/">Project page</a>
                        /
                        <a href="https://arxiv.org/abs/2406.10114">arXiv</a>
                        /
                        <a href="https://openaccess.thecvf.com/content/CVPR2024/html/de_Geus_Task-aligned_Part-aware_Panoptic_Segmentation_through_Joint_Object-Part_Representations_CVPR_2024_paper">CVF</a>
                        /
                        <a href="https://github.com/tue-mps/tapps/">Code</a>
                    </li>

                    <li>
                        <strong>Off-Policy Action Anticipation in Multi-Agent Reinforcement Learning</strong><br>
                        Ariyan Bighashdel, <strong>Daan de Geus</strong>, Pavol Jancura, Gijs Dubbelman<br>
                        <em>JMLR</em>, 2024 <br>
                        <a href="https://arxiv.org/abs/2304.01447">arXiv</a>
                        /
                        <a href="http://www.jmlr.org/papers/v25/23-0413.html">JMLR</a>
                    </li>

                    <li>
                        <strong>How to Benchmark Vision Foundation Models for Semantic Segmentation?</strong><br>
                        Tommie Kerssies, <strong>Daan de Geus</strong>, Gijs Dubbelman<br>
                        <em>CVPR Workshops</em>, 2024 <br>
                        <a href="https://www.tue-mps.org/benchmark-vfm-ss/">Project page</a>
                        /
                        <a href="https://arxiv.org/abs/2404.12172">arXiv</a>
                        /
                        <a href="https://openaccess.thecvf.com/content/CVPR2024W/2WFM/html/Kerssies_How_to_Benchmark_Vision_Foundation_Models_for_Semantic_Segmentation_CVPRW_2024_paper.html">CVF</a>
                        /
                        <a href="https://github.com/tue-mps/benchmark-vfm-ss/">Code</a>
                    </li>

                    <li>
                        <strong>Exploring the Benefits of Vision Foundation Models for Unsupervised Domain Adaptation</strong><br>
                        Brun&oacute; B. Englert, Fabrizio J. Piva, Tommie Kerssies, <strong>Daan de Geus</strong>, Gijs Dubbelman<br>
                        <em>CVPR Workshops</em>, 2024 <br>
                        <a href="https://arxiv.org/abs/2406.09896">arXiv</a>
                        /
                        <a href="https://openaccess.thecvf.com/content/CVPR2024W/2WFM/html/Englert_Exploring_the_Benefits_of_Vision_Foundation_Models_for_Unsupervised_Domain_CVPRW_2024_paper">CVF</a>
                    </li>

                    <li>
                        <strong>The BRAVO Semantic Segmentation Challenge Results in UNCV2024</strong><br>
                       Tuan-Hung Vu, Eduardo Valle, Andrei Bursuc, Tommie Kerssies, <strong>Daan de Geus</strong>, Gijs Dubbelman, Long Qian, Bingke Zhu, Yingying Chen, Ming Tang, Jinqiao Wang, Tom&aacute;&scaron; Voj&iacute;&rcaron;, Jan &Scaron;ochman, Ji&rcaron;&iacute; Matas, Michael Smith, Frank Ferrie, Shamik Basu, Christos Sakaridis, Luc Van Gool<br>
                        <em>ECCV Workshops</em>, 2024 <br>
                        <a href="https://arxiv.org/abs/2409.15107">arXiv</a>
                    </li>

                    <li>
                        <strong>Advances in Scene Understanding: Towards Efficient Image Segmentation at Multiple Abstraction Levels</strong><br>
                        <strong>Daan de Geus</strong><br>
                        <em>PhD Thesis</em><br>
                        <a href="https://research.tue.nl/en/publications/advances-in-scene-understanding-towards-efficient-image-segmentat">PDF</a>
                    </li>

                    <li>
                        <strong>First Place Solution to the ECCV 2024 BRAVO Challenge: Evaluating Robustness of Vision Foundation Models for Semantic Segmentation</strong><br>
                        Tommie Kerssies, <strong>Daan de Geus</strong>, Gijs Dubbelman<br>
                        <em>arXiv, 2024</em> (Presented at <em>ECCV 2024 Workshop on Unceritanty Quantification for Computer Vision</em>)<br>
                        <a href="https://arxiv.org/abs/2409.17208">arXiv</a>
                        /
                        <a href="https://github.com/tue-mps/benchmark-vfm-ss">Code</a>
                    </li>
                </ul>
                </p>
                
              </td>
            </tr>


            <tr>
              <td style="vertical-align:top">
                <p>
                <strong>2023</strong><br>
                <ul>
                    <li>
                        <strong>Content-aware Token Sharing for Efficient Semantic Segmentation with Vision Transformers</strong><br>
                        Chenyang Lu*, <strong>Daan de Geus</strong>*, Gijs Dubbelman<br>
                        <em>CVPR</em>, 2023<br>
                        <a href="https://www.tue-mps.org/CTS/">Project page</a>
                        /
                        <a href="https://arxiv.org/abs/2306.02095">arXiv</a>
                        /
                        <a href="https://openaccess.thecvf.com/content/CVPR2023/html/Lu_Content-Aware_Token_Sharing_for_Efficient_Semantic_Segmentation_With_Vision_Transformers_CVPR_2023_paper">CVF</a>
                        /
                        <a href="https://github.com/tue-mps/cts-segmenter">Code</a>
                    </li>

                    <li>
                        <strong>Intra-Batch Supervision for Panoptic Segmentation on High-Resolution Images</strong><br>
                        <strong>Daan de Geus</strong>, Gijs Dubbelman<br>
                        <em>WACV</em>, 2023<br>
                        <a href="https://ddegeus.github.io/intra-batch-supervision/">Project page</a>
                        /
                        <a href="https://arxiv.org/abs/2304.08222">arXiv</a>
                        /
                        <a href="https://openaccess.thecvf.com/content/WACV2023/html/de_Geus_Intra-Batch_Supervision_for_Panoptic_Segmentation_on_High-Resolution_Images_WACV_2023_paper.html">CVF</a>
                        /
                        <a href="https://ddegeus.github.io/intra-batch-supervision/#code">Code</a>
                    </li>

                    <li>
                        <strong>Empirical Generalization Study: Unsupervised Domain Adaptation vs. Domain Generalization Methods for Semantic Segmentation in the Wild</strong><br>
                        Fabrizio J. Piva, <strong>Daan de Geus</strong>, Gijs Dubbelman<br>
                        <em>WACV</em>, 2023<br>
                        <a href="https://openaccess.thecvf.com/content/WACV2023/html/Piva_Empirical_Generalization_Study_Unsupervised_Domain_Adaptation_vs._Domain_Generalization_Methods_WACV_2023_paper">CVF</a>
                    </li>

                    <li>
                        <strong>Coordinating Fully-Cooperative Agents Using Hierarchical Learning Anticipation</strong><br>
                        Ariyan Bighashdel, <strong>Daan de Geus</strong>, Pavol Jancura, Gijs Dubbelman<br>
                        <em>arXiv</em>, 2023 (Presented at <em>AAMAS 2023 Workshop on Optimization and Learning in Multi-Agent Systems</em>)<br>
                        <a href="https://arxiv.org/abs/2303.08307">arXiv</a>
                    </li>
                </ul>
                </p>
                
              </td>
            </tr>

            <tr>
              <td style="vertical-align:top">
                <p>
                <strong>2021</strong><br>
                <ul>
                    <li>
                        <strong>Part-aware Panoptic Segmentation</strong><br>
                        <strong>Daan de Geus</strong>*, Panagiotis Meletis*, Chenyang Lu, Xiaoxiao Wen, Gijs Dubbelman<br>
                        <em>CVPR</em>, 2021<br>
                        <a href="https://arxiv.org/abs/2106.06351">arXiv</a>
                        /
                        <a href="https://openaccess.thecvf.com/content/CVPR2021/html/de_Geus_Part-Aware_Panoptic_Segmentation_CVPR_2021_paper.html">CVF</a>
                        /
                        <a href="https://github.com/pmeletis/panoptic_parts">Code &amp; Dataset</a>
                    </li>
                </ul>
                </p>
                
              </td>
            </tr>

            <tr>
              <td style="vertical-align:top">
                <p>
                <strong>2020</strong><br>
                <ul>
                    <li>
                        <strong>Fast Panoptic Segmentation Network</strong><br>
                        <strong>Daan de Geus</strong>, Panagiotis Meletis, Gijs Dubbelman<br>
                        <em>Robotics and Automation Letters</em>, 2020<br>
                        <a href="https://arxiv.org/abs/1910.03892">arXiv</a>
                        /
                        <a href="https://ieeexplore.ieee.org/abstract/document/8972471">IEEE</a>
                    </li>

                    <li>
                        <strong>Proactive Risk Navigation System for Real-World Urban Intersections</strong><br>
                        Tim Puphal, Benedict Flade, <strong>Daan de Geus</strong>, Julian Eggert<br>
                        <em>IEEE ITSC</em>, 2020<br>
                        <a href="https://arxiv.org/abs/2303.07886">arXiv</a>
                        /
                        <a href="https://ieeexplore.ieee.org/abstract/document/9294452">IEEE</a>
                    </li>

                    <li>
                        <strong>Cityscapes-Panoptic-Parts and PASCAL-Panoptic-Parts datasets for Scene Understanding</strong><br>
                        Panagiotis Meletis, Xiaoxiao Wen, Chenyang Lu, <strong>Daan de Geus</strong>, Gijs Dubbelman<br>
                        <em>arXiv</em>, 2020 (Technical report)<br>
                        <a href="https://arxiv.org/abs/2004.07944">arXiv</a>
                        /
                        <a href="https://github.com/pmeletis/panoptic_parts">Dataset</a>
                    </li>
                </ul>
                </p>
                
              </td>
            </tr>


            <tr>
              <td style="vertical-align:top">
                <p>
                <strong>2019</strong><br>
                <ul>
                    <li>
                        <strong>Single Network Panoptic Segmentation for Street Scene Understanding</strong><br>
                        <strong>Daan de Geus</strong>, Panagiotis Meletis, Gijs Dubbelman<br>
                        <em>IEEE IV Symposium</em>, 2019<br>
                        <a href="https://arxiv.org/abs/1902.02678">arXiv</a>
                        /
                        <a href="https://ieeexplore.ieee.org/abstract/document/8813788">IEEE</a>
                    </li>
                </ul>
                </p>
                
              </td>
            </tr>

            <tr>
              <td style="vertical-align:top">
                <p>
                <strong>2018</strong><br>
                <ul>
                    <li>
                        <strong>Panoptic Segmentation with a Joint Semantic and Instance Segmentation Network</strong><br>
                        <strong>Daan de Geus</strong>, Panagiotis Meletis, Gijs Dubbelman<br>
                        <em>arXiv</em>, 2018 (Technical report for <em>ECCV 2018 COCO + Mapillary Joint Recognition Challenge</em>)<br>
                        <a href="https://arxiv.org/abs/1809.02110">arXiv</a>
                    </li>
                </ul>
                </p>
                
              </td>
            </tr>


            <tr>
              <td style="vertical-align:top" align="center">
                <p>
                  <a href="#top">Take me to the top &uArr;</a>
                </p>
                
              </td>
            </tr>

        </tbody></table>

        </td>
      </tr>
    </tbody></table>
  </body>

</html>